{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_root = '../../MyData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing 10-k file descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['CIK', 'Year', 'Content', 'Word_Count', 'Token_Count', 'Summary',\n",
       "       'Error', 'ErrorMessage', 'Summary_Token_Count', 'Summary_Word_Count',\n",
       "       'Embeddings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# item1 contains descriptions from 10-k files\n",
    "file_path = data_root + 'raw_data/df_stage4_5years.csv'\n",
    "item1 = pd.read_csv(file_path)\n",
    "item1 = item1[item1['Year']==2021]\n",
    "item1 = item1.drop(['Unnamed: 0.1', 'Unnamed: 0'], axis=1)\n",
    "print(len(item1))\n",
    "item1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CIK  Year                                            Content  \\\n",
      "1235   861459  2021  Item 1. BUSINESS Introduction Granite Construc...   \n",
      "3845   861459  2021  Item 1. BUSINESS Introduction Granite Construc...   \n",
      "831    886128  2021  Item 1.BUSINESSIndex to Item 1. BUSINESS PageF...   \n",
      "1021   886128  2021  Item 1.     BUSINESS   Index to Item 1. BUSINE...   \n",
      "2912   898437  2021  Item1. Business 5 PartII Item7. Managements Di...   \n",
      "6386   898437  2021  ITEM 1. BUSINESS Overview Founded in 1992, Ani...   \n",
      "1550   943819  2021  ITEM 1. BUSINESS.OverviewUnited Airlines Holdi...   \n",
      "2935   943819  2021  Item 1. Business. Overview MAA, an S&P 500 com...   \n",
      "6040   943819  2021  ITEM 1 BUSINESS General We are a global leader...   \n",
      "4407  1590715  2021  Item 1. Business. Overview When we formed our ...   \n",
      "5177  1590715  2021  Item 1. Business. Overview When we formed our ...   \n",
      "\n",
      "      Word_Count  Token_Count  \\\n",
      "1235       25469        29993   \n",
      "3845       26004        30666   \n",
      "831         1727         2374   \n",
      "1021       23466        29465   \n",
      "2912       11164        13765   \n",
      "6386        5181         6311   \n",
      "1550       10273        13169   \n",
      "2935        4513         5446   \n",
      "6040       15091        18528   \n",
      "4407       13243        16132   \n",
      "5177       13243        16132   \n",
      "\n",
      "                                                Summary  Error  ErrorMessage  \\\n",
      "1235  **Summary of Granite Construction Company Busi...    0.0           NaN   \n",
      "3845  **Summary of Granite Construction Company Busi...    0.0           NaN   \n",
      "831   **Summary of Item 1: Business Overview**\\n\\n**...    0.0           NaN   \n",
      "1021  ### Summary of Item 1: Business\\n\\n**Core Busi...    0.0           NaN   \n",
      "2912  **Summary of Anika Therapeutics, Inc. Business...    0.0           NaN   \n",
      "6386  **Summary of Anika Therapeutics, Inc. Business...    0.0           NaN   \n",
      "1550  **Summary of United Airlines Holdings, Inc. (U...    0.0           NaN   \n",
      "2935  **Summary of Item 1: Business Overview**\\n\\n**...    0.0           NaN   \n",
      "6040  **Summary of ResMed Inc. Business Overview (It...    0.0           NaN   \n",
      "4407  **Summary of Item 1: Business**\\n\\n**Overview:...    0.0           NaN   \n",
      "5177  **Summary of Item 1: Business**\\n\\n**Overview:...    0.0           NaN   \n",
      "\n",
      "      Summary_Token_Count  Summary_Word_Count  \\\n",
      "1235                  687                 505   \n",
      "3845                  590                 431   \n",
      "831                   579                 458   \n",
      "1021                  683                 475   \n",
      "2912                  766                 499   \n",
      "6386                  773                 527   \n",
      "1550                  649                 486   \n",
      "2935                  459                 345   \n",
      "6040                  725                 526   \n",
      "4407                  580                 450   \n",
      "5177                  600                 470   \n",
      "\n",
      "                                             Embeddings  \n",
      "1235  [0.005930817220360041, 0.010183613747358322, 0...  \n",
      "3845  [0.005812405608594418, 0.0010421487968415022, ...  \n",
      "831   [0.0029625254683196545, -0.006495341192930937,...  \n",
      "1021  [-0.00039266914245672524, -0.01439815759658813...  \n",
      "2912  [-0.016832245513796806, 0.026567725464701653, ...  \n",
      "6386  [-0.016669191420078278, 0.02598797157406807, 0...  \n",
      "1550  [-0.06954989582300186, -0.007926642894744873, ...  \n",
      "2935  [0.0375671461224556, 0.035842668265104294, 0.0...  \n",
      "6040  [0.0047199055552482605, 0.02963181398808956, 0...  \n",
      "4407  [0.018716150894761086, 0.0005908565944992006, ...  \n",
      "5177  [0.0156477689743042, 0.005799402948468924, 0.0...  \n",
      "Empty DataFrame\n",
      "Columns: [CIK, Year, Content, Word_Count, Token_Count, Summary, Error, ErrorMessage, Summary_Token_Count, Summary_Word_Count, Embeddings]\n",
      "Index: []\n",
      "1219\n"
     ]
    }
   ],
   "source": [
    "# There are several firms that have more than one embedding\n",
    "duplicates = item1[item1['CIK'].duplicated(keep=False)]\n",
    "print(duplicates.sort_values(by=\"CIK\"))\n",
    "\n",
    "# I only retain first one here\n",
    "item1 = item1.drop_duplicates(subset='CIK', keep='first')\n",
    "print(item1[item1['CIK'].duplicated(keep=False)])\n",
    "print(len(item1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cik', 'Year', 'item1', 'item1_word_count', 'item1_token_count',\n",
       "       'item1_summary', 'Error', 'ErrorMessage', 'item1_summary_token_count',\n",
       "       'item1_summary_word_count', 'item1_embeddings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item1 = item1.rename(columns={'Content':'item1',\n",
    "                          'Word_Count':'item1_word_count',\n",
    "                          'Token_Count':'item1_token_count',\n",
    "                          'Summary':'item1_summary',\n",
    "                          'Summary_Token_Count':'item1_summary_token_count',\n",
    "                          'Summary_Word_Count':'item1_summary_word_count',\n",
    "                          'Embeddings':'item1_embeddings',\n",
    "                          'CIK':'cik'})\n",
    "item1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Compustat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract compustat data from 2021\n",
    "\n",
    "# file_path = '../item1_and_financial_variable/compustat_entire_2005_2022.csv'\n",
    "# df = pd.read_csv(file_path)\n",
    "# print(len(df))\n",
    "\n",
    "# df = df[df['fyear'] == 2021]\n",
    "# file_path = '../item1_and_financial_variable/multi-view/compustat_2021.csv'\n",
    "# df.to_csv(file_path, index=False)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12656\n",
      "8564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xu Tongzhou\\AppData\\Local\\Temp\\ipykernel_16792\\1563438152.py:3: DtypeWarning: Columns (10,30,948,975) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  compustat2021 = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Obtain compustat data from 2021\n",
    "file_path = data_root + 'compustat_2021.csv'\n",
    "compustat2021 = pd.read_csv(file_path)\n",
    "compustat2021 = compustat2021.rename(columns={'fyear': 'Year'})\n",
    "print(len(compustat2021))\n",
    "\n",
    "# remove rows that contain nan in 'cik', 'Year', 'tic'\n",
    "compustat2021 = compustat2021.dropna(subset=['cik', 'Year', 'tic'])\n",
    "print(len(compustat2021))\n",
    "\n",
    "# Here, I only retain 'tic' in compustat.\n",
    "compustat2021 = compustat2021[['cik', 'Year', 'tic']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out 1197 firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "int64\n",
      "int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "compustat2021['cik'] = compustat2021[\"cik\"].astype(\"int64\")\n",
    "compustat2021['Year'] = compustat2021['Year'].astype(\"int64\")\n",
    "\n",
    "print(item1['cik'].dtype)\n",
    "print(compustat2021['cik'].dtype)\n",
    "\n",
    "print(item1['Year'].dtype)\n",
    "print(compustat2021['Year'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1381\n",
      "1197\n"
     ]
    }
   ],
   "source": [
    "set1197 = pd.merge(item1, compustat2021, on=['cik', 'Year'])\n",
    "print(len(set1197))\n",
    "\n",
    "# Some duplicate from compustats, droped those duplicated records\n",
    "set1197 = set1197.drop_duplicates(subset=[\"cik\", \"Year\"])\n",
    "print(len(set1197))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing sp, yh, sa descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1401\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cik</th>\n",
       "      <th>conm</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>tic</th>\n",
       "      <th>SIC_Division</th>\n",
       "      <th>SIC_MajorGroup</th>\n",
       "      <th>NAICS_Sector</th>\n",
       "      <th>NAICS_SubSector</th>\n",
       "      <th>hoberg_fic25</th>\n",
       "      <th>...</th>\n",
       "      <th>SP_TOPICTAG</th>\n",
       "      <th>SP_CATEGORIES</th>\n",
       "      <th>SP_CUSIP</th>\n",
       "      <th>SP_TICKER</th>\n",
       "      <th>SP_EXCHANGE_TICKER</th>\n",
       "      <th>SP_COMPANY_NAME</th>\n",
       "      <th>_merge</th>\n",
       "      <th>word_count</th>\n",
       "      <th>YH_BUS_DESC</th>\n",
       "      <th>SA_BUS_DESC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>702325</td>\n",
       "      <td>FIRST MIDWEST BANCORP INC</td>\n",
       "      <td>11896</td>\n",
       "      <td>FMBI</td>\n",
       "      <td>H</td>\n",
       "      <td>60</td>\n",
       "      <td>52</td>\n",
       "      <td>522.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Anti-Fraud; EDI (Electronic Data Interchange);...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320867104</td>\n",
       "      <td>FMBI</td>\n",
       "      <td>NASDAQGM:FMBI</td>\n",
       "      <td>First Midwest Bancorp, Inc.</td>\n",
       "      <td>both</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16040</td>\n",
       "      <td>CABOT CORP</td>\n",
       "      <td>2593</td>\n",
       "      <td>CBT</td>\n",
       "      <td>D</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>325.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>CleanTech; Pollution Control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127055101</td>\n",
       "      <td>CBT</td>\n",
       "      <td>NYSE:CBT</td>\n",
       "      <td>Cabot Corporation</td>\n",
       "      <td>both</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cabot Corporation operates as a specialty chem...</td>\n",
       "      <td>Cabot Corporation operates as a specialty chem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1156039</td>\n",
       "      <td>ELEVANCE HEALTH INC</td>\n",
       "      <td>145046</td>\n",
       "      <td>ELV</td>\n",
       "      <td>H</td>\n",
       "      <td>63</td>\n",
       "      <td>52</td>\n",
       "      <td>524.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Outpatient Care; Employee Benefits; Chronic Di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>036752103</td>\n",
       "      <td>ELV</td>\n",
       "      <td>NYSE:ELV</td>\n",
       "      <td>Elevance Health, Inc.</td>\n",
       "      <td>both</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elevance Health, Inc., together with its subsi...</td>\n",
       "      <td>Elevance Health, Inc., together with its subsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1488813</td>\n",
       "      <td>CUSTOMERS BANCORP INC</td>\n",
       "      <td>170396</td>\n",
       "      <td>CUBI</td>\n",
       "      <td>H</td>\n",
       "      <td>60</td>\n",
       "      <td>52</td>\n",
       "      <td>522.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Consumer Lending; Fintech; Blockchain; Digital...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23204G100</td>\n",
       "      <td>CUBI</td>\n",
       "      <td>NYSE:CUBI</td>\n",
       "      <td>Customers Bancorp, Inc.</td>\n",
       "      <td>both</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Customers Bancorp, Inc. operates as the bank h...</td>\n",
       "      <td>Customers Bancorp, Inc. operates as the bank h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>785161</td>\n",
       "      <td>ENCOMPASS HEALTH CORP</td>\n",
       "      <td>12589</td>\n",
       "      <td>EHC</td>\n",
       "      <td>I</td>\n",
       "      <td>80</td>\n",
       "      <td>62</td>\n",
       "      <td>622.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Health Diagnostics; Neurology</td>\n",
       "      <td>Health Care, Medical, Rehabilitation</td>\n",
       "      <td>29261A100</td>\n",
       "      <td>EHC</td>\n",
       "      <td>NYSE:EHC</td>\n",
       "      <td>Encompass Health Corporation</td>\n",
       "      <td>both</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Encompass Health Corporation provides post-acu...</td>\n",
       "      <td>Encompass Health Corporation provides post-acu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cik                       conm   gvkey   tic SIC_Division  \\\n",
       "0           0   702325  FIRST MIDWEST BANCORP INC   11896  FMBI            H   \n",
       "1           1    16040                 CABOT CORP    2593   CBT            D   \n",
       "2           2  1156039        ELEVANCE HEALTH INC  145046   ELV            H   \n",
       "3           3  1488813      CUSTOMERS BANCORP INC  170396  CUBI            H   \n",
       "4           4   785161      ENCOMPASS HEALTH CORP   12589   EHC            I   \n",
       "\n",
       "   SIC_MajorGroup  NAICS_Sector  NAICS_SubSector  hoberg_fic25  ...  \\\n",
       "0              60            52            522.0           NaN  ...   \n",
       "1              28            32            325.0          11.0  ...   \n",
       "2              63            52            524.0          14.0  ...   \n",
       "3              60            52            522.0           4.0  ...   \n",
       "4              80            62            622.0          14.0  ...   \n",
       "\n",
       "                                         SP_TOPICTAG  \\\n",
       "0  Anti-Fraud; EDI (Electronic Data Interchange);...   \n",
       "1                       CleanTech; Pollution Control   \n",
       "2  Outpatient Care; Employee Benefits; Chronic Di...   \n",
       "3  Consumer Lending; Fintech; Blockchain; Digital...   \n",
       "4                      Health Diagnostics; Neurology   \n",
       "\n",
       "                          SP_CATEGORIES   SP_CUSIP  SP_TICKER  \\\n",
       "0                                   NaN  320867104       FMBI   \n",
       "1                                   NaN  127055101        CBT   \n",
       "2                                   NaN  036752103        ELV   \n",
       "3                                   NaN  23204G100       CUBI   \n",
       "4  Health Care, Medical, Rehabilitation  29261A100        EHC   \n",
       "\n",
       "  SP_EXCHANGE_TICKER               SP_COMPANY_NAME  _merge word_count  \\\n",
       "0      NASDAQGM:FMBI   First Midwest Bancorp, Inc.    both        NaN   \n",
       "1           NYSE:CBT             Cabot Corporation    both        NaN   \n",
       "2           NYSE:ELV         Elevance Health, Inc.    both        NaN   \n",
       "3          NYSE:CUBI       Customers Bancorp, Inc.    both        NaN   \n",
       "4           NYSE:EHC  Encompass Health Corporation    both        NaN   \n",
       "\n",
       "                                         YH_BUS_DESC  \\\n",
       "0                                                NaN   \n",
       "1  Cabot Corporation operates as a specialty chem...   \n",
       "2  Elevance Health, Inc., together with its subsi...   \n",
       "3  Customers Bancorp, Inc. operates as the bank h...   \n",
       "4  Encompass Health Corporation provides post-acu...   \n",
       "\n",
       "                                         SA_BUS_DESC  \n",
       "0                                                NaN  \n",
       "1  Cabot Corporation operates as a specialty chem...  \n",
       "2  Elevance Health, Inc., together with its subsi...  \n",
       "3  Customers Bancorp, Inc. operates as the bank h...  \n",
       "4  Encompass Health Corporation provides post-acu...  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptions from sp, yh and sa\n",
    "\n",
    "file_path = data_root + 'checked_data/final_df_cleaned_retained.csv'\n",
    "\n",
    "sp_yh_sa = pd.read_csv(file_path)\n",
    "\n",
    "print(len(sp_yh_sa))\n",
    "\n",
    "sp_yh_sa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging 10-k with sp, yh, sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197\n",
      "1401\n"
     ]
    }
   ],
   "source": [
    "print(len(set1197))\n",
    "print(len(sp_yh_sa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1189\n",
      "1197\n",
      "1189\n",
      "1197\n",
      "{'VOLT', 'FLOW', 'FUN', 'CAMP', 'AMRS', 'NLS', 'BBBY', 'TEN'}\n"
     ]
    }
   ],
   "source": [
    "# There are 8 firms that don't have record in sp_yh_sa (final_df_cleaned), and no duplicated firm\n",
    "inner_merged_1_df = pd.merge(set1197, sp_yh_sa, on=['cik', 'tic'])\n",
    "print(len(inner_merged_1_df))\n",
    "left_merged_1_df = pd.merge(set1197, sp_yh_sa, how=\"left\", on=['cik', 'tic'])\n",
    "print(len(left_merged_1_df))\n",
    "\n",
    "inner_set = set(inner_merged_1_df['tic'])\n",
    "print(len(inner_set))\n",
    "left_set = set(left_merged_1_df['tic'])\n",
    "print(len(left_set))\n",
    "print(left_set - inner_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77       FLT\n",
      "98      SMLP\n",
      "327     NYCB\n",
      "452       RE\n",
      "670      NLS\n",
      "732      FUN\n",
      "738      AUD\n",
      "748      GLT\n",
      "827     BBBY\n",
      "925     FLOW\n",
      "1008     TEN\n",
      "1014    AMRS\n",
      "1023    CAMP\n",
      "1154    VOLT\n",
      "1194    PACW\n",
      "Name: tic, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# But there are actually totaly 15 rows that don't have any description from sp, yh or sa\n",
    "print(left_merged_1_df[left_merged_1_df['SP_BUSINESS_DESCRIPTION'].isna() & \n",
    "          left_merged_1_df['SP_LONG_BUSINESS_DESCRIPTION'].isna() &\n",
    "          left_merged_1_df['YH_BUS_DESC'].isna() &\n",
    "          left_merged_1_df['SA_BUS_DESC'].isna()]['tic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cik', 'Year', 'item1', 'item1_word_count', 'item1_token_count',\n",
       "       'item1_summary', 'Error', 'ErrorMessage', 'item1_summary_token_count',\n",
       "       'item1_summary_word_count', 'item1_embeddings', 'tic', 'Unnamed: 0',\n",
       "       'conm', 'gvkey', 'SIC_Division', 'SIC_MajorGroup', 'NAICS_Sector',\n",
       "       'NAICS_SubSector', 'hoberg_fic25', 'hoberg_fic100', 'GICS_Sector',\n",
       "       'GICS_IndustryGroup', 'GICS_Industry', 'cusip', 'SP_ENTITY_NAME',\n",
       "       'SP_ENTITY_ID', 'SP_BUSINESS_DESCRIPTION',\n",
       "       'SP_LONG_BUSINESS_DESCRIPTION', 'SP_TOPICTAG', 'SP_CATEGORIES',\n",
       "       'SP_CUSIP', 'SP_TICKER', 'SP_EXCHANGE_TICKER', 'SP_COMPANY_NAME',\n",
       "       '_merge', 'word_count', 'YH_BUS_DESC', 'SA_BUS_DESC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "left_merged_1_df contains:\n",
    "    basic: cik, tic\n",
    "    introductions: item1(original content, summary content, embedding), SP(short, long), YH, SA\n",
    "    classification code: SIC, NAICS, GICS\n",
    "'''\n",
    "left_merged_1_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Orbis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1163\n",
      "Index(['Unnamed: 0', 'company_name', 'tic', 'trade_description',\n",
      "       'products_services', 'primary_business', 'main_activity',\n",
      "       'main_products', 'description_history', 'full_overview'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "file_path = data_root + 'checked_data/orbis_filtered.csv'\n",
    "orbis = pd.read_csv(file_path)\n",
    "orbis = orbis.rename(columns={'ticker': 'tic'})\n",
    "\n",
    "# There are only 1163 firms in Orbis\n",
    "print(len(orbis))\n",
    "print(orbis.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Orbis with previous left_merged_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004\n",
      "1197\n",
      "1004\n",
      "1197\n",
      "number of firms that don't have record in orbis: 193\n"
     ]
    }
   ],
   "source": [
    "# There are 193 firms that don't have record in orbis, and no duplicated firm\n",
    "inner_merged_2_df = pd.merge(left_merged_1_df, orbis[['tic', 'products_services', 'full_overview']], on=['tic'])\n",
    "print(len(inner_merged_2_df))\n",
    "left_merged_2_df = pd.merge(left_merged_1_df, orbis[['tic', 'products_services', 'full_overview']], how=\"left\", on=['tic'])\n",
    "print(len(left_merged_2_df))\n",
    "\n",
    "inner_set = set(inner_merged_2_df['tic'])\n",
    "print(len(inner_set))\n",
    "left_set = set(left_merged_2_df['tic'])\n",
    "print(len(left_set))\n",
    "print(f\"number of firms that don't have record in orbis: {len(left_set - inner_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77       FLT\n",
      "98      SMLP\n",
      "327     NYCB\n",
      "452       RE\n",
      "670      NLS\n",
      "732      FUN\n",
      "738      AUD\n",
      "748      GLT\n",
      "827     BBBY\n",
      "925     FLOW\n",
      "1008     TEN\n",
      "1014    AMRS\n",
      "1023    CAMP\n",
      "1154    VOLT\n",
      "1194    PACW\n",
      "Name: tic, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# But there are actually totaly 15 rows that don't have any description from sp, yh, sa or orbis\n",
    "print(left_merged_2_df[left_merged_2_df['SP_BUSINESS_DESCRIPTION'].isna() & \n",
    "          left_merged_2_df['SP_LONG_BUSINESS_DESCRIPTION'].isna() &\n",
    "          left_merged_2_df['YH_BUS_DESC'].isna() &\n",
    "          left_merged_2_df['SA_BUS_DESC'].isna() & \n",
    "          left_merged_2_df['products_services'].isna() &\n",
    "          left_merged_2_df['full_overview'].isna()]['tic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "121 firms' \"trade_description\" are short texts like: \"Bank Holding Company\", \"INSURANCE\"\n",
    "Therefore, maybe using full_overview is a better.\n",
    "'''\n",
    "def check_orbis_length(row):\n",
    "    if type(row['trade_description']) == str and len(row['trade_description']) < 100:\n",
    "        # print(row['trade_description'])\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "left_merged_2_df.apply(check_orbis_length, axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_merged_2_df = left_merged_2_df.rename(columns={'products_services': 'ORBIS_PROD_SERV',\n",
    "                                                    'full_overview': 'ORBIS_OVERVIEW',\n",
    "                                                    'SP_BUSINESS_DESCRIPTION': 'SP_SHORT_DESC',\n",
    "                                                    'SP_LONG_BUSINESS_DESCRIPTION': 'SP_LONG_DESC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cik', 'Year', 'item1', 'item1_word_count', 'item1_token_count',\n",
       "       'item1_summary', 'Error', 'ErrorMessage', 'item1_summary_token_count',\n",
       "       'item1_summary_word_count', 'item1_embeddings', 'tic', 'Unnamed: 0',\n",
       "       'conm', 'gvkey', 'SIC_Division', 'SIC_MajorGroup', 'NAICS_Sector',\n",
       "       'NAICS_SubSector', 'hoberg_fic25', 'hoberg_fic100', 'GICS_Sector',\n",
       "       'GICS_IndustryGroup', 'GICS_Industry', 'cusip', 'SP_ENTITY_NAME',\n",
       "       'SP_ENTITY_ID', 'SP_SHORT_DESC', 'SP_LONG_DESC', 'SP_TOPICTAG',\n",
       "       'SP_CATEGORIES', 'SP_CUSIP', 'SP_TICKER', 'SP_EXCHANGE_TICKER',\n",
       "       'SP_COMPANY_NAME', '_merge', 'word_count', 'YH_BUS_DESC', 'SA_BUS_DESC',\n",
       "       'ORBIS_PROD_SERV', 'ORBIS_OVERVIEW'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_merged_2_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_merged_2_df.to_csv(\"data/merged_1197.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
